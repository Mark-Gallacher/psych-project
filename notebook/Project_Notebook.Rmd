---
title: "R Notebook"
output: 
  html_notebook:
    toc: true
---
#### Libraries

--- 
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(pwr) # for Power calculation
library(TOSTER) # for TOST equivalance testing

source(here::here("other-scripts", "optim_equiv_func.R")) # to get optim_equiv function
```

```{r User-Defined Function, include=FALSE}
## NEED TO CHANGE THE VARIABLE NAMES TO BE MORE HELPFUL, as sample_size_vec, SHOULD BE THE VECTOR USED TO ITERATE ROW A COLUMN
## MOVE FUNCTIONS TO SEPARATE SCRIPT AND ADD MORE COMMENTS THERE, TO KEEP NOTEBOOK TIDY
## RENAME FUNCTIONS TO BE GENERAL AND INFORMATIVE
## THEN ADD TO GITHUB
## ADD A READ.ME DOC to explain folders
## 

# After for-loop power calculations, the output needs to be organised, so there is a column with sample size, and pivoted to make plotting the data easier.
tidy_output_with_n <- function(array, 
                               value_colname, 
                               name_colname, 
                               iter_var, 
                               sample_size_vec){
  
  if (is.character(value_colname) & (length(value_colname) == 1)){ 
    value_name <- value_colname
  }else{ stop("value_colname should be a character of length 1, in quotation marks") }
  
  if (is.character(name_colname) & (length(name_colname) == 1)){ 
    name_name <- name_colname
  }else{ stop("name_colname should be a character of length 1, in quotation marks") }
  
  colnames(array) <- iter_var
  
  df_output <- array |> 
    as_tibble() |> 
    mutate(n = sample_size_vec) |> 
    pivot_longer(cols = -n, 
                 names_to = {{ name_name }}, 
                 values_to = {{ value_name }})
  
  df_output
}


get_power_or_effect <- function(iter_var, 
                                sample_size_vec,
                                alpha = 0.05,
                                get_power = TRUE){

  len_sample <- length(sample_size_vec)
  len_iter <- length(iter_var)
    
  output <- array(NA, dim = c(len_sample, len_iter))
  
if(get_power == TRUE){
  iter_var_1 = iter_var
  iter_var_2 = NULL
  result = 4 # power is the 4th output from pwr.t.test
}else{
  iter_var_1 = NULL
  iter_var_2 = iter_var
  result = 2 # cohen's d is the 2nd output from pwr.t.test
  }

for(n in 1:len_sample){
  for(i in 1:len_iter){
    
    d = iter_var_1[i]
    power = iter_var_2[i]
    
    output[n, i] <- pwr.t.test(sig.level = alpha, 
                               d = d, 
                               n = sample_size_vec[n], 
                               power = power, 
                               type="paired",
                               alternative="two.sided")[[result]]
    }
}
  output  
}

get_tidy_power_or_effect <- function(iter_var, 
                                     sample_size_vec, 
                                     value_colname, 
                                     name_colname, 
                                     get_power = TRUE){
  
 output <-  get_power_or_effect(iter_var = iter_var,
                                sample_size_vec = sample_size_vec,
                                get_power = get_power) |> 
            tidy_output_with_n(iter_var = iter_var, 
                               sample_size_vec = sample_size_vec, 
                               value_colname = value_colname,
                               name_colname = name_colname)
  
 output
  
}
 
```
# How Power and Effect relate to a *Static* alpha level, for a given sample size

### Setting up the parametres for Power Calculation
```{r}
# Sample Size
sample_size <- c(5, seq(1, 9.5, 0.5) %o% 10^(1:3))
l_sample <- length(sample_size)

# Effect Size - One default, and One list
cohens_d <- 0.5
many_cohens_d <- seq(0.1, 1, 0.1)
l_many_cohen <- length(many_cohens_d)

# Power - One default, and One list
power <- 0.9
many_power <- seq(0.8, 0.95, 0.05)
l_many_power <- length(many_power)

# Alpha - One default, and One list
alpha <- 0.05
many_alpha <- c(1 %o% 10^(-1:-6))
l_many_alpha <- length(many_alpha)

cat("Sample Size :", sample_size)
cat("Cohen's d :", many_cohens_d)
cat("Power :", many_power)
cat("Alpha :", many_alpha)
```
## Power vs Sample Size, for a given Effect Size

#### Calculating Power while iterating through different effect and sample sizes
```{r}
pwr_by_es_df <- get_tidy_power_or_effect(iter_var = many_cohens_d,
                                         sample_size_vec = sample_size, 
                                         value_colname = "power", 
                                         name_colname = "effect_size", 
                                         get_power = TRUE)

head(pwr_by_es_df)
```
### Plotting Power Curves
```{r}
pwr_by_es_df |> 
  ggplot(aes(x = n, y = power, colour = effect_size))+
  geom_line(alpha = 0.5, size = 1.5)+
  scale_x_log10(name = "Sample Size")+
  scale_y_continuous(name = "Power")+
  guides(colour = guide_legend(title = "Cohen's d"))+
  ggtitle("Power vs Sample Size, for different Cohen's d")+
  theme_minimal()
```
## Effect Size vs Sample Size, for a given Power

#### Calculating Effect Size while iterating through different levels of Power and sample sizes
```{r}
es_by_pwr_df <- get_tidy_power_or_effect(iter_var = many_power,
                                         sample_size_vec = sample_size, 
                                         value_colname = "effect_size", 
                                         name_colname = "power", 
                                         get_power = FALSE)

head(es_by_pwr_df)
```

###  Plotting Effect Size Curves

```{r}
es_by_pwr_df |> 
  ggplot(aes(x = n, y = effect_size, colour = power))+
  geom_line(alpha = 0.5, size = 1.5)+
  scale_x_log10(name = "Sample Size")+
  scale_y_continuous(name = "Effect Size")+
  guides(colour = guide_legend(title = "Power"))+
  ggtitle("Effect Size vs Sample Size, for different Powers")+
  theme_minimal()
```

---

```{r}

```
# How Power and Effect relate to a *Dynamic* alpha level, for a given sample size 

## Alpha vs Sample Size, where *alpha~N~ = min(alpha, beta)*
```{r}
dyn_alpha <- array(NA, dim = c(l_sample, l_many_cohen))    # array for new alphas  
power_array <- array(NA, dim = c(l_sample, l_many_cohen))  # array for powers to find beta, for new alphas
power_dyn_a <- array(NA, dim = c(l_sample, l_many_cohen))  # array for powers from new alphas 
cohen_dyn_a <- array(NA, dim = c(l_sample, l_many_power))  # array for effect sizes from new alphas 
```
#### Calculating Power while iterating through different Effect and sample sizes - to find beta, then *min(alpha, beta)*
```{r}
for(n in 1:l_sample){
  for(d in 1:l_many_cohen){
    power_array[n, d] <- pwr.t.test(sig.level = alpha, 
                                  d = many_cohens_d[d], 
                                  n = sample_size[n], 
                                  power = NULL, 
                                  type="paired",
                                  alternative="two.sided")$power
    
    beta_value <- 1-power_array[n,d]
    dyn_alpha[n,d] <- min(alpha, beta_value)
  }
}

# Raw Output from Loop, columns are different Effect Sizes, Rows are different Sample Sizes
head(dyn_alpha)
```

#### Changing Column Names, Adding Sample Size and Reorganising tibble for visualisations
```{r}
dyn_alpha_df <- tidy_output_with_n(array = dyn_alpha,
                   iter_var = many_cohens_d,
                   sample_size_vec = sample_size, 
                   value_colname = "alpha",
                   name_colname = "effect_size")

head(dyn_alpha_df)

```
###  Plotting Alpha Curves
```{r}
dyn_alpha_df |> 
  ggplot(aes(x = n, y = alpha, colour = effect_size))+
  geom_line(alpha = 0.5, size = 1.5)+
  geom_point(alpha = 0.5, size = 1.5)+
  scale_x_log10(name = "Sample Size")+
  scale_y_continuous(name = "Alpha")+
  guides(colour = guide_legend(title = "Effect Size"))+
  ggtitle("Dynamic Alpha Levels - min(alpha, beta)")+
  theme_minimal()
```

```{r}
## Sample alphas were negative and some were zero - but pwr.t.test needs alpha to be a positive non-zero number.
## The smallest alpha in the dyn_alpha was 1e-16, so that would be our new minimum
f_dyn_alpha <- dyn_alpha |>
  as_tibble() |> 
  mutate(across(everything(), ~if_else(. <= 0, 1e-16,.)))

for(n in 1:l_sample){
  for(d in 1:l_many_cohen){
    a <- as.numeric(f_dyn_alpha[n,d])
    power_dyn_a[n, d] <- pwr.t.test(sig.level = a, 
                                  d = many_cohens_d[d], 
                                  n = sample_size[n], 
                                  power = NULL, 
                                  type="paired",
                                  alternative="two.sided")$power

  }
}
```
#### Changing Column Names, Adding Sample Size and Reorganising tibble for visualisations
```{r}
power_dyn_a_df <- tidy_output_with_n(array = power_dyn_a, 
                                     value_colname = "power", 
                                     name_colname = "effect_size", 
                                     iter_var = many_cohens_d,
                                     sample_size_vec = sample_size)

head(power_dyn_a_df)
```
### Plotting Power at different effect and sample sizes, while Alpha is now dynamic
```{r}
power_dyn_a_df |> 
  ggplot(aes(x = n, y = power, colour = effect_size))+
  geom_line(alpha = 0.5, size = 1.5)+
  geom_point(alpha = 0.5, size = 1.5)+
  scale_x_log10(name = "Sample Size")+
  scale_y_continuous(name = "Power")+
  guides(colour = guide_legend(title = "Effect Size"))+
  ggtitle("Power Using Dynamic Alpha Levels - min(alpha, beta)")+
  theme_minimal()
```

```{r}
for(n in 1:l_sample){
  for(p in 1:l_many_power){
    a <- as.numeric(f_dyn_alpha[n,p])
    cohen_dyn_a[n, p] <- pwr.t.test(sig.level = a, 
                                  d = NULL, 
                                  n = sample_size[n], 
                                  power = many_power[p], 
                                  type="paired",
                                  alternative="two.sided")$d

  }
}
```
#### Changing Column Names, Adding Sample Size and Reorganising tibble for visualisations
```{r}
cohen_dyn_a_df <- tidy_output_with_n(array = cohen_dyn_a, 
                                     value_colname = "effect_size", 
                                     name_colname = "power", 
                                     iter_var = many_power,
                                     sample_size_vec = sample_size)

head(cohen_dyn_a_df)
```

```{r}
cohen_dyn_a_df |> 
  ggplot(aes(x = n, y = effect_size, colour = power))+
  geom_line(alpha = 0.5, size = 1.5)+
  geom_point(alpha = 0.5, size = 1.5)+
  geom_hline(yintercept = c(0.1,0.2), size = 1.5, alpha = 0.4)+
  scale_x_log10(name = "Sample Size")+
  scale_y_continuous(name = "Effect Size")+
  guides(colour = guide_legend(title = "Power"))+
  ggtitle("Effect Size Using Dynamic Alpha Levels - min(alpha, beta)")+
  theme_minimal()
```


```{r}
alpha_zero_to_one <- seq(0.01, 1, 0.01)
beta_zero_to_one <- array(NA, dim = c(length(alpha_zero_to_one), l_many_cohen))


for (d in 1:l_many_cohen){
  for (a in 1:length(alpha_zero_to_one)){

    pwr <- pwr::pwr.t.test(n = 10, d = many_cohens_d[d], sig.level = alpha_zero_to_one[a])$power
    beta = 1 - pwr
    
    beta_zero_to_one[a,d] <- beta
  }
}

beta_alpha_diff <- tidy_output_with_n(array = beta_zero_to_one, 
                                      iter_var = many_cohens_d, 
                                      value_colname = "beta", 
                                      name_colname = "effect_size", 
                                      sample_size_vec = alpha_zero_to_one
                                      )
```

```{r}

beta_alpha_diff |> 
  ggplot(aes(x = n, y = beta, color = effect_size))+
  geom_line(size = 2, alpha = .3)+
  geom_point(size = 1, alpha = .6)+
  scale_x_continuous(name = "Alpha")+
  scale_y_continuous(name = "Beta")+
  guides(colour = guide_legend(title = "Effect Size"))+
  ggtitle("Relationship between Alpha and Beta, for given Effect Size")+
  theme_minimal()

```

```{r}
# Alpha and Beta - weighted equally
beta_alpha_mean <- beta_alpha_diff |> 
  mutate(mn = (n + beta)/2)

beta_alpha_mean |> 
  ggplot(aes(x = n, y = mn, color = effect_size))+
  geom_line(size = 2, alpha = .3)+
  geom_point(size = 1, alpha = .6)+
  scale_x_continuous(name = "Alpha")+
  scale_y_continuous(name = "(Alpha + Beta) / 2")+
  guides(colour = guide_legend(title = "Effect Size"))+
  ggtitle("Relationship between (Alpha + Beta)/2 and Alpha, for given Effect Size")+
  theme_minimal()

```

```{r}
# Alpha and Beta - Weighted differently
c = 4

beta_alpha_weighted <- beta_alpha_mean |> 
  mutate(wd = ((c*n) + beta)/(c*2))

beta_alpha_weighted |> 
  ggplot(aes(x = n, y = wd, color = effect_size))+
  geom_line(size = 1, alpha = .6)+
  # geom_point(size = 1, alpha = .6)+
  scale_x_continuous(name = "Alpha", limits = c(0,0.5))+
  scale_y_continuous(name = "(Alpha + Beta) / 2")+
  guides(colour = guide_legend(title = "Effect Size"))+
  ggtitle("Relationship between (Alpha + Beta)/2 and Alpha, for given Effect Size")+
  theme_minimal()
```
# Equivalence Testing

## TOST - Using TOSTER package
```{r, warning = FALSE, message=FALSE}

sample = c(25,50,100)
m = 100 # mean of both groups set to 100
d = c(1:50, -1:-50)/10 # smaller increments for smoother graph
sd = 10
alpha = 0.05

result <- array(NA, dim = c(length(d), 3*length(sample)))


for(n in 1:length(sample)){
  for(diff in 1:length(d)){
    output <- TOSTER::tsum_TOST(
      n1 = sample[n], n2 = sample[n],
      m1 = m, m2 = m+d[diff], 
      sd1 = sd, sd2 = sd, 
      r12 = 0, # no correlation, so we get a simplified cohen's d
      hypothesis = "EQU",
      low_eqbound = -0.2,
      high_eqbound = 0.2,
      alpha = alpha,
      eqbound_type = "SMD", 
      bias_correction = FALSE, 
      paired = TRUE)

  result[diff, 3*n-2] <- output$TOST$p.value[1] # t test
  result[diff, 3*n-1] <- output$TOST$p.value[2] # lower 
  result[diff, 3*n] <- output$TOST$p.value[3]   # upper
  }
}

```

#### Tidying Output for better Visualisation
```{r}
result_tibble <- result |> 
  as_tibble() |> 
  rename("t_test_25" = V1,"lower_25" = V2,"upper_25" = V3,
         "t_test_50" = V4,"lower_50" = V5,"upper_50" = V6,
         "t_test_100" = V7,"lower_100" = V8,"upper_100" = V9
         ) |>
  mutate(diff = d) |> 
  pivot_longer(cols = -10,
               names_to = "t", 
               values_to = "p") |> 
  mutate(n = str_extract(t, pattern = "[0-9]+"),
         t = str_extract(t, pattern = "[t_]*[a-z]+")
         )
```

#### PLotting Cohen's d vs p-values with various sample sizes
```{r}

result_tibble |> 
  ggplot(aes(x = diff/sd, y = p, colour = t, linetype = n))+
  geom_line(size = 1.2, alpha = 0.7)+
  geom_hline(yintercept = 0.05)+
  ggtitle("TOST and t-test, p-value at different mean differences (SD = 10) at \nThree sample sizes (25,50,100)")+
  scale_x_continuous(name = "Cohen's d",breaks = seq(-.5, .5, .1))+
  theme_minimal()

```

### Looking at Larger Sample Sizes

```{r, message=FALSE}
sample = c(25,50, 100, 500, 1000)
m = 100 # mean of both groups set to 100
d = c(1:50, -1:-50)/10 # smaller increments for smoother graph
sd = 10
alpha = 0.05

result_2 <- array(NA, dim = c(length(d), 3*length(sample)))


for(n in 1:length(sample)){
  for(diff in 1:length(d)){
    output <- TOSTER::tsum_TOST(
      n1 = sample[n], n2 = sample[n],
      m1 = m, m2 = m+d[diff], 
      sd1 = sd, sd2 = sd, 
      r12 = 0, # no correlation, so we get a simplified cohen's d
      hypothesis = "EQU",
      low_eqbound = -0.2,
      high_eqbound = 0.2,
      alpha = alpha,
      eqbound_type = "SMD", 
      bias_correction = FALSE, 
      paired = TRUE)

  result_2[diff, 3*n-2] <- output$TOST$p.value[1] # t test
  result_2[diff, 3*n-1] <- output$TOST$p.value[2] # lower 
  result_2[diff, 3*n] <- output$TOST$p.value[3]   # upper
  }
}
```
#### Tidying Output to make Visualisations better
```{r}
result_tibble_2 <- result_2 |> 
  as_tibble() |> 
  rename("t_test_25" = V1,"lower_25" = V2,"upper_25" = V3,
         "t_test_50" = V4,"lower_50" = V5,"upper_50" = V6,
         "t_test_100" = V7,"lower_100" = V8,"upper_100" = V9,
         "t_test_500" = V10,"lower_500" = V11,"upper_500" = V12,
         "t_test_1000" = V13,"lower_1000" = V14,"upper_1000" = V15
         ) |>
  mutate(diff = d) |> 
  pivot_longer(cols = -diff,
               names_to = "t", 
               values_to = "p") |> 
  mutate(n = str_extract(t, pattern = "[0-9]+"),
         t = str_extract(t, pattern = "[t_]*[a-z]+")
         )
```
#### PLotting Cohen's d and p-values for small to large sample sizes
```{r}
result_tibble_2 |> 
  filter(t != "t_test") |> 
  ggplot(aes(x = diff/sd, y = p, colour = n, linetype = t))+
  geom_line(size = 1.2, alpha = 0.7)+
  geom_hline(yintercept = 0.05)+
  ggtitle("TOST, p-value at different mean differences (SD = 10) at \nFive sample sizes (10,50,100,500,1000)")+
  labs(caption = 
      "Remember that the upper and lower bounds are 0.2 Cohen's d and we assume the correlation is zero, 
       this reflects a more theoretical experiment. We need both tests to return a p value less than alpha 
       for 'significant' equivalance.")+
  scale_y_continuous(limits = c(0,0.20))+
  scale_x_continuous(name = "Cohen's d",breaks = seq(-.5, .5, .1))+
  theme_minimal()
```
### WIP - "Optimal" Testing for equivalance
```{r, eval=FALSE}

sample = c(100, 100, 100, 100, 100)
m = 100 # mean of both groups set to 100
d = c(1:1000)/100 # smaller increments for smoother graph
sd = 10
alpha = 0.05

result_3 <- array(NA, dim = c(length(d), 2*length(sample)))

for(s in 1:length(sample)){
  for(diff in 1:length(d)){
    n1 = rnorm(sample[s], mean = m, sd = sd)
    n2 = rnorm(sample[s], mean = m+d[diff], sd = sd)
    
    output <- optim_equiv(n1, n2, margin = 2.828)
    
    result_3[diff, 2*s-1] <- output[1] # tost
    result_3[diff, 2*s] <- output[2] # optim
  }
}

```

```{r, eval=FALSE}
result_tibble_3 <- result_3 |> 
  as_tibble() |> 
  rename(
    "tost_10a" = V1, "optim_10a" = V2,
    "tost_10b" = V3, "optim_10b" = V4,
    "tost_10c" = V5, "optim_10c" = V6,
    "tost_10d" = V7, "optim_10d" = V8,
    "tost_10e" = V9, "optim_10e" = V10, 
         # "tost_50" = V3, "optim_50" = V4,
         # "tost_100" = V5, "optim_100" = V6,
         ) |> 
  mutate(diff = d) |> 
  pivot_longer(cols = (-diff),
               names_to = "test", 
               values_to = "p") |> 
    mutate(n = str_extract(test, pattern = "[0-9]+"),
           t = str_extract(test, pattern = "[t_]*[a-z]+")
         )


```

```{r, eval=FALSE}
result_tibble_3 |> 
  ggplot(aes(x = diff, y = p, colour = t))+
  geom_point(size = 1.2, alpha = 0.4)+
  geom_hline(yintercept = 0.05)+
  theme_minimal()
```

